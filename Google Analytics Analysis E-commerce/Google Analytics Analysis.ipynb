{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "afae17b9",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b172db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "from apiclient.discovery import build\n",
    "import httplib2\n",
    "from oauth2client import client\n",
    "from oauth2client import file\n",
    "from oauth2client import tools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime, date, time, timezone\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import cm\n",
    "import re\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import stats\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#Scraper\n",
    "def scraper():\n",
    "    URL = \"\" # Portugese e-learning platform website\n",
    "    DOMAIN = \"\" # Portugese e-learning platform website\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    results = soup.find_all(\"article\", class_=\"ee-post\")\n",
    "\n",
    "    links = []\n",
    "    for result in results: \n",
    "        links.append(result.find(\"a\")[\"href\"])\n",
    "\n",
    "    params = []\n",
    "    df = pd.DataFrame()\n",
    "    dic_pt = {'DURATION' : 'DURAÇÃO', 'PRICE' : 'PREÇO', 'SCHEDULE' : 'HORÁRIO', 'LANGUAGE' : 'IDIOMA', 'SESSIONS' : 'Sessões', 'FORMAT' : 'Formato'}\n",
    "\n",
    "    for link in tqdm(links):\n",
    "        dic = {}\n",
    "        page = requests.get(link)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "        title = soup.find_all(\"h3\", class_=\"elementor-icon-box-title\")\n",
    "        description = soup.find_all(\"p\", class_=\"elementor-icon-box-description\")\n",
    "\n",
    "        t = []\n",
    "        for i in title:\n",
    "            try:\n",
    "                t.append(i.find('span').text.strip())\n",
    "            except:\n",
    "                t.append(\"\")\n",
    "\n",
    "        if any(x in dic_pt.keys() for x in t):\n",
    "            for i, n in enumerate(t):\n",
    "                try: \n",
    "                    t[i] = dic_pt[n]\n",
    "                except: \n",
    "                    t[i] = \"\"\n",
    "\n",
    "        d = []\n",
    "        for i in description:\n",
    "            try:\n",
    "                d.append(i.text.strip())\n",
    "            except:\n",
    "                d.append(\"\")\n",
    "\n",
    "        params += list(zip(t, d))\n",
    "        for a, b in params:\n",
    "            if a in dic_pt.values():\n",
    "                dic[a] = b\n",
    "\n",
    "        try: \n",
    "            date = soup.find(\"div\", class_=\"elementor-element elementor-element-0339c3d dc-has-condition dc-condition-empty elementor-widget elementor-widget-text-editor\").div.ul.li.text.strip()\n",
    "        except: \n",
    "            date  = 0 \n",
    "\n",
    "        try: \n",
    "            title = soup.title.text\n",
    "        except: \n",
    "            title = \"\"\n",
    "\n",
    "        try: \n",
    "            published = soup.find(\"meta\", property=\"article:modified_time\")[\"content\"]\n",
    "        except: \n",
    "            published = \"\"\n",
    "\n",
    "        try: \n",
    "            url = soup.find(\"meta\", property=\"og:url\")[\"content\"].replace(DOMAIN,\"\")\n",
    "        except: \n",
    "            url = \"\"\n",
    "\n",
    "        dic[\"Date\"] = date\n",
    "        dic[\"Title\"] = title\n",
    "        dic[\"Published\"] = published\n",
    "        dic[\"URL\"] = url\n",
    "\n",
    "\n",
    "        df = df.append(dic, ignore_index=True)\n",
    "        \n",
    "    df['course_index'] = np.arange(len(df))\n",
    "\n",
    "        \n",
    "    df = df.set_index('URL')\n",
    "    df = df.loc[df.index != '']\n",
    "    df.to_csv(r\"cursos.csv\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# GA360 v4 API\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/analytics.readonly']\n",
    "CLIENT_SECRETS_PATH = '' # Path to client_secrets.json file.\n",
    "VIEW_ID = '' # Google Analytics View Id\n",
    "START_DATE = \"2020-09-01\"\n",
    "END_DATE = \"2021-11-20\"\n",
    "N = 50 # TRESHOLD OF PAGEVIEWS - DEPENDENT ON TIMEFRAME\n",
    "\n",
    "def initialize_analyticsreporting():\n",
    "\n",
    "    # Parse command-line arguments.\n",
    "    parser = argparse.ArgumentParser(\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        parents=[tools.argparser])\n",
    "    flags = parser.parse_args([])\n",
    "\n",
    "    # Set up a Flow object to be used if we need to authenticate.\n",
    "    flow = client.flow_from_clientsecrets(\n",
    "        CLIENT_SECRETS_PATH, scope=SCOPES,\n",
    "        message=tools.message_if_missing(CLIENT_SECRETS_PATH))\n",
    "\n",
    "    # Prepare credentials, and authorize HTTP object with them.\n",
    "    # If the credentials don't exist or are invalid run through the native client\n",
    "    # flow. The Storage object will ensure that if successful the good\n",
    "    # credentials will get written back to a file.\n",
    "    storage = file.Storage('analyticsreporting.dat')\n",
    "    credentials = storage.get()\n",
    "    if credentials is None or credentials.invalid:\n",
    "        credentials = tools.run_flow(flow, storage, flags)\n",
    "    http = credentials.authorize(http=httplib2.Http())\n",
    "\n",
    "    # Build the service object.\n",
    "    analytics = build('analyticsreporting', 'v4', http=http)\n",
    "\n",
    "    return analytics\n",
    "\n",
    "def get_report(analytics, dims, metrics):\n",
    "  # Use the Analytics Service Object to query the Analytics Reporting API V4.\n",
    "    requests_list =  [{\n",
    "            'viewId': VIEW_ID,\n",
    "            'dateRanges': [{'startDate': START_DATE, 'endDate': END_DATE}],\n",
    "            'dimensions': [{'name': name} for name in dims],\n",
    "            'metrics': [{'expression': exp} for exp in metrics],\n",
    "        \"samplingLevel\": \"LARGE\",\n",
    "        \"pageSize\": 100000\n",
    "    }]\n",
    "    return analytics.reports().batchGet(body={'reportRequests':requests_list }).execute()\n",
    "\n",
    "def ga_response_dataframe(response, dims, metrics):\n",
    "    data_dic = {f\"{i}\": [] for i in dims + metrics}\n",
    "    for report in response.get('reports', []):\n",
    "        rows = report.get('data', {}).get('rows', [])\n",
    "        for row in rows:\n",
    "            for i, key in enumerate(dims):\n",
    "                data_dic[key].append(row.get('dimensions', [])[i]) # Get dimensions\n",
    "            dateRangeValues = row.get('metrics', [])\n",
    "            for values in dateRangeValues:\n",
    "                all_values = values.get('values', []) # Get metric values\n",
    "                for i, key in enumerate(metrics):\n",
    "                    data_dic[key].append(all_values[i])\n",
    "\n",
    "    df = pd.DataFrame(data=data_dic)\n",
    "    df.columns = [col.split(':')[-1] for col in df.columns]\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c024ddfc",
   "metadata": {},
   "source": [
    "## starting_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da185b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def start_date(result):\n",
    "    pt_months_original = ['janeiro', 'fevereiro', 'março', 'abril', 'maio', 'junho', 'julho', 'agosto', 'setembro', 'outubro', 'novembro', 'dezembro']\n",
    "    today = date.today()\n",
    "    pt_months = pt_months_original[today.month-1:] + pt_months_original[:today.month]\n",
    "\n",
    "    for url in np.unique(result.index.values):\n",
    "        \n",
    "        date_ = result.loc[url]['Date']\n",
    "\n",
    "        if date_ != '0':\n",
    "            if type(date_) == np.ndarray:\n",
    "                date_ = date_[0]\n",
    "\n",
    "            d = int(re.search(r\"D*(\\d+)\", str(date_)).group())\n",
    "        \n",
    "            res = [ele for ele in pt_months if (ele in date_.lower())]\n",
    "\n",
    "            m = pt_months_original.index(res[0])+1\n",
    "            y = today.year\n",
    "            \n",
    "            if m < today.month:\n",
    "                y += 1\n",
    "\n",
    "            starting_date = datetime(y, m, d)\n",
    "\n",
    "            result.loc[result.index == url, 'starting_date'] = starting_date\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcdd93c",
   "metadata": {},
   "source": [
    "# Creating DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf834a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "analytics = initialize_analyticsreporting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558f5d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMS = ['ga:date', 'ga:city']\n",
    "METRICS = ['ga:sessions']\n",
    "# ga:date\n",
    "\n",
    "response = get_report(analytics, DIMS, METRICS)\n",
    "\n",
    "df = ga_response_dataframe(response, DIMS, METRICS)\n",
    "\n",
    "# df = df[df['pagePath'].apply( lambda x: True if x.startswith('/curso/') else False )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16466cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[(df.city == \"Lisbon\") | (df.city == \"Porto\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c67ee82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"..\\..\\SEO_CausalInference.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5b6d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMS = ['ga:pagePath', 'ga:date']\n",
    "METRICS = ['ga:pageviews']\n",
    "\n",
    "response = get_report(analytics, DIMS, METRICS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6f553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ga_response_dataframe(response, DIMS, METRICS)\n",
    "\n",
    "df = df[df['pagePath'].apply( lambda x: True if x.startswith('/curso/') else False )]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609ef3fa",
   "metadata": {},
   "source": [
    "## Narrowing data down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28611467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pageviews = pd.to_numeric(df.pageviews)\n",
    "df.date = df.date.astype('datetime64[ns]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f3a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = df.groupby(by=[\"pagePath\"]).sum().reset_index()\n",
    "df_groupby = df_groupby[df_groupby['pageviews'] > N]\n",
    "\n",
    "df = df[df.pagePath.isin(df_groupby.pagePath.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad97aa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraper = scraper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955aacc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('pagePath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b2bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scraper = start_date(df_scraper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aa6ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df, df_scraper, left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97a9980",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result['Published'] = pd.to_datetime(result['Published']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce60e622",
   "metadata": {},
   "source": [
    "## Visualizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38375e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.Published = result.Published.astype(object).where(result.Published.notnull(), np.NaN)\n",
    "result.Published = pd.to_datetime(result['Published'])\n",
    "result.starting_date = result.starting_date.astype(object).where(result.starting_date.notnull(), np.NaN)\n",
    "    \n",
    "for i in np.unique(result.index.values):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.plot(result[result.index == i]['date'], result[result.index == i]['pageviews'])\n",
    "    \n",
    "    print(type(result[result.index == i]['Published'][0]))\n",
    "        \n",
    "    # you can add here as many lines as you want\n",
    "    try:\n",
    "        plt.axvline(result[result.index == i]['starting_date'][0], color=\"red\", linestyle=\"--\")\n",
    "    except: \n",
    "        pass\n",
    "    try: \n",
    "        plt.axvline(result[result.index == i]['Published'][0], color=\"green\", linestyle=\"--\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    plt.title(i)\n",
    "    plt.show()\n",
    "    \n",
    "# get information on actual performance\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e498aa02",
   "metadata": {},
   "source": [
    "## ALL BROKEN DOWN INTO NAME SAKES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108228ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = np.unique(result.Title.values).tolist()\n",
    "result['starting_date'] = pd.to_datetime(result['starting_date'])\n",
    "result['Published'] = pd.to_datetime(result['Published'])\n",
    "\n",
    "l = []\n",
    "for i, t in enumerate(result.Title.values): \n",
    "    l.append(result.Title.values[i][0:result.Title.values[i].find('-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2a5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "result['Title'] = l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d04800",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_agg = result.groupby(['date', 'Title'])['pageviews'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f718dbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "    \n",
    "plt.figure(figsize=(15, 8))\n",
    "\n",
    "color = iter(cm.rainbow(np.linspace(0, 1, len(np.unique(result_agg.Title.values)))))\n",
    "    \n",
    "for n, i in enumerate(np.unique(result_agg.Title.values)):\n",
    "    c =  next(color)\n",
    "    #plt.axvline(result_agg[result_agg.Title == i]['starting_date'][0], color = c)  \n",
    "    #plt.axvline(result_agg[result_agg.Title == i]['Published'][0], color = c)\n",
    "        \n",
    "    plt.plot(result_agg[result_agg.Title == i]['date'], result_agg[result_agg.Title == i]['pageviews'], label = i, color = c)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# AGGR INTO SAME NAMES AND MEAN IT - AND THEN BREAK THEM DOWN INTO THEIR PARTS AND COMPARE THOSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5613a7b9",
   "metadata": {},
   "source": [
    "## EACH GROUP OF EQUALLY NAMES COURSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d94865",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s = np.unique(result.Title.values).tolist()\n",
    "result['starting_date'] = pd.to_datetime(result['starting_date'])\n",
    "result['Published'] = pd.to_datetime(result['Published'])\n",
    "\n",
    "result.Published = result.Published.astype(object).where(result.Published.notnull(), np.NaN)\n",
    "result.starting_date = result.starting_date.astype(object).where(result.starting_date.notnull(), np.NaN)\n",
    "\n",
    "ts = np.unique(result.Title.values)\n",
    "unique_titles = []\n",
    "for t in ts: \n",
    "    unique_titles.append(t[:t.find('-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f898c5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#result['Title'] = result['Title'].apply(lambda x: x.rstrip())\n",
    "result['Title'] = result['Title'].apply(lambda x: x[:x.find('-')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c003b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "for title in np.unique(result['Title'].values):\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.title(title)\n",
    "    \n",
    "    df_plot = result[result['Title'] == title]\n",
    "    color = iter(cm.rainbow(np.linspace(0, 1, len(np.unique(df_plot.index.values)))))\n",
    "\n",
    "    for i in np.unique(df_plot.index.values):\n",
    "        c = next(color)\n",
    "        \n",
    "        plt.axvline(df_plot[df_plot.index == i]['Published'][0], color = c, linestyle=\"dashed\")\n",
    "        plt.axvline(df_plot[df_plot.index == i]['starting_date'][0], color = c, linestyle=\"dashdot\")  \n",
    "        \n",
    "        plt.plot(df_plot[df_plot.index == i]['date'], df_plot[df_plot.index == i]['pageviews'], color = c)\n",
    "        #print(df_plot[df_plot.index == i]['Published'][0], df_plot[df_plot.index == i]['starting_date'][0])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2c68c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the average number of pageviews +- 7 days after publishing and before start\n",
    "# maybe segmentize the entire time span in three parts and see % of total pageviews in each\n",
    "\n",
    "# maybe also align all e.g. start dates and accordingly all daily pageviews and map that \n",
    "\n",
    "# cross reference this with attendance at class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cafeba",
   "metadata": {},
   "source": [
    "## Title word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6794bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.unique(result.Title.values).tolist()\n",
    "\n",
    "s_ = ''\n",
    "for i, t in enumerate(s): \n",
    "    s_ += s[i][0:s[i].find('-')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2a814",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "s_ = s_.lower()\n",
    "tags = ['curso', 'de', 'para', 'for', 'em', '|', 'lisbon', 'digital', 'school', 'curso']\n",
    "\n",
    "for tag in tags:\n",
    "    s_ = re.sub(r'\\b' + tag + r'\\b', '', s_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75922c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_ = [x for x in s_.split(\" \") if x]\n",
    "\n",
    "dict(sorted(Counter(s_).items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b110104",
   "metadata": {},
   "source": [
    "## Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4b914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Every page visit is considered a conversion - ii dont see how to track/ get information on whether a form as submitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8852e55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMS = ['ga:pagePath']\n",
    "METRICS = ['ga:goalCompletionsAll', 'ga:pageviews', 'ga:uniquePageviews', 'ga:pageviewsPerSession', 'ga:entrances', 'ga:entranceRate', 'ga:timeOnPage', 'ga:exits', 'ga:exitRate', 'ga:bounceRate']\n",
    "# ga:date\n",
    "\n",
    "response = get_report(analytics, DIMS, METRICS)\n",
    "\n",
    "df = ga_response_dataframe(response, DIMS, METRICS)\n",
    "df = df[df['pagePath'].apply( lambda x: True if x.startswith('/curso/') else False )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820eb0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pageviews = pd.to_numeric(df.pageviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52f37ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groupby = df.groupby(by=[\"pagePath\"]).sum().reset_index()\n",
    "df = df[df.pagePath.isin(df_groupby.pagePath.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c295db40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_scraper = scraper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2897a454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2410c1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('pagePath')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ce5e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(df, df_scraper, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78513636",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b52cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = result[['course_index', 'pageviews', 'uniquePageviews', 'pageviewsPerSession',\n",
    "       'entranceRate', 'timeOnPage', 'exitRate', 'bounceRate','starting_date',\n",
    "       'DURAÇÃO', 'Formato', 'HORÁRIO', 'PREÇO',\n",
    "       'Sessões', 'IDIOMA']]\n",
    "\n",
    "hm.loc[:, ['DURAÇÃO']] = hm['DURAÇÃO'].apply(lambda x: int(re.search(r\"D*(\\d+)\", x).group()))\n",
    "hm.loc[:, ['PREÇO']] = hm['PREÇO'].apply(lambda x: int(re.findall(r\"D*(\\d+)\", x)[-1]))\n",
    "hm.loc[:, ['weekday']] = result['starting_date'].apply(lambda x: 1 if x.weekday() < 5 else 0)\n",
    "\n",
    "\n",
    "hm.loc[hm['Sessões'] == 'Várias', 'Sessões'] = 0       \n",
    "hm.loc[hm['Formato'] == 'Online live', 'Formato'] = 'Online em Directo'  \n",
    "hm.loc[hm['HORÁRIO'] == 'Pós-laboral, Sábados', 'HORÁRIO'] = 'Pós-laboral' \n",
    "hm.loc[hm['HORÁRIO'] == 'Working hours', 'HORÁRIO'] = 'Laboral'  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf621482",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in hm.columns: \n",
    "    hm.loc[:, col] = pd.to_numeric(hm[col], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b545d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = pd.get_dummies(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892456f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d892bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['pageviews', 'uniquePageviews', 'pageviewsPerSession', 'entranceRate', 'timeOnPage', 'exitRate', 'bounceRate']\n",
    "\n",
    "rows = ['course_index', 'DURAÇÃO', 'PREÇO', 'Sessões','weekday',\n",
    "       'Formato_Online em Directo', 'Formato_Presencial', 'HORÁRIO_Laboral', 'HORÁRIO_Pós-laboral', 'HORÁRIO_Sábados',\n",
    "        'IDIOMA_Português']\n",
    "\n",
    "if 'IDIOMA_English' in hm.columns: \n",
    "    rows.append('IDIOMA_English')\n",
    "else:\n",
    "    rows.remove('IDIOMA_Português')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eede96b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "corr = hm.corr()\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "\n",
    "sns.heatmap(corr.loc[rows, cols], annot=True, fmt=\".2f\", cmap='Blues',\n",
    "           vmin=-1, vmax=1, cbar_kws={\"shrink\": .8})\n",
    "# yticks\n",
    "plt.yticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRACK HOW MANY OF THEM LEAD TO CONVERSION a\n",
    "# 1 = oline em directo\n",
    "\n",
    "# maybe categorieze them into the different lifecycle stages they are in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08401847",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm['DURAÇÃO'].str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8495f8b",
   "metadata": {},
   "source": [
    "## Pairplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc1bd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hm = result[['pageviews', 'uniquePageviews', 'pageviewsPerSession', 'entranceRate', 'timeOnPage', 'exitRate', 'bounceRate', \n",
    "        'DURAÇÃO', 'PREÇO', 'Sessões', 'HORÁRIO']]\n",
    "\n",
    "hm.update(hm.loc[:, 'DURAÇÃO'].apply(lambda x: int(re.search(r\"D*(\\d+)\", x).group())))\n",
    "hm.update(hm.loc[:, 'PREÇO'].apply(lambda x: int(re.findall(r\"D*(\\d+)\", x)[-1])))\n",
    "\n",
    "hm.loc[hm['Sessões'] == 'Várias', 'Sessões'] = 0       \n",
    "hm.loc[hm['HORÁRIO'] == 'Pós-laboral, Sábados', 'HORÁRIO'] = 'Pós-laboral' \n",
    "hm.loc[hm['HORÁRIO'] == 'Working hours', 'HORÁRIO'] = 'Laboral' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea10dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in hm.columns: \n",
    "    hm.loc[:, col] = pd.to_numeric(hm[col], errors='ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01837320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers - not because they are actually such but to enable interpretationo f visualizations\n",
    "hm.iloc[:,:-1] = hm.iloc[:,:-1][(np.abs(stats.zscore(hm.iloc[:,:-1])) < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0f9704",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.pairplot(hm, hue=\"HORÁRIO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2dd0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  FOR EACH OF THE VISUALIZATIONS THE DATE RANGE SHOULD BE FROM PUBLISHED TO DEADLINE (FIRST DAY OF CLASS?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e68472",
   "metadata": {},
   "source": [
    "## N-Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48af4289",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../sitemap_ngrams.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d137f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[(df.Count > 10) & (df.Ngram.str.len() > 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ba1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMS = ['ga:goalCompletionLocation', 'ga:goalPreviousStep1', 'ga:goalPreviousStep2', 'ga:goalPreviousStep3']\n",
    "METRICS = ['ga:goalStartsAll', 'ga:goalCompletionsAll', 'ga:goalAbandonsAll']\n",
    "\n",
    "response = get_report(analytics, DIMS, METRICS)\n",
    "\n",
    "df = ga_response_dataframe(response, DIMS, METRICS)\n",
    "\n",
    "df = df[df['goalCompletionLocation'].apply( lambda x: True if x.startswith('/curso/') else False )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3df0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdc18d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['goalCompletionLocation'] == '/curso/acessibilidade-digital-directo-online/']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7855d37",
   "metadata": {},
   "source": [
    "# Traffic Sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186bb6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMS = ['ga:referralPath', 'ga:fullReferrer', 'ga:campaign', 'ga:medium', 'ga:source']\n",
    "METRICS = []\n",
    "\n",
    "response = get_report(analytics, DIMS, METRICS)\n",
    "\n",
    "df = ga_response_dataframe(response, DIMS, METRICS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484113aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42884734",
   "metadata": {},
   "source": [
    "# Page Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f73d0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMS = ['ga:hostname', 'ga:pagePath', 'ga:pageTitle', 'ga:landingPagePath', 'ga:secondPagePath', 'ga:exitPagePath', 'ga:previousPagePath', 'ga:pageDepth']\n",
    "METRICS = ['ga:entranceRate', 'ga:pageviews', 'ga:pageviewsPerSession', 'ga:uniquePageviews', 'ga:timeOnPage', 'ga:avgTimeOnPage', 'ga:exitRate', 'ga:bounceRate']\n",
    "\n",
    "response = get_report(analytics, DIMS, METRICS)\n",
    "\n",
    "df = ga_response_dataframe(response, DIMS, METRICS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aacb676",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df.columns: \n",
    "    df.loc[:, col] = pd.to_numeric(df[col], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c093fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df.shape[0]\n",
    "VARIABLE = '' # Replace with entities hostname\n",
    "df = df.loc[df.hostname == VARIABLE].drop(columns=['hostname'])\n",
    "print(f\"Percentage of rows lost: {(b - df.shape[0]) / b * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0244e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df.shape[0]\n",
    "df = df.loc[np.abs(stats.zscore(df['pageDepth'])) < 3, :]\n",
    "print(f\"Percentage of rows lost: {(b - df.shape[0]) / b * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7334421d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = df.shape[0]\n",
    "df = df.loc[np.abs(stats.zscore(df['avgTimeOnPage'] / df.pageDepth)) < 3, :]\n",
    "df = df.loc[(np.abs(stats.zscore(df['timeOnPage'] / df.pageDepth)) < 3), :]\n",
    "print(f\"Percentage of rows lost: {(b - df.shape[0]) / b * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b881691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryconvert(value):\n",
    "    if isinstance(value, str) and value.startswith('/?ee_search_query'):\n",
    "        try:\n",
    "            return \"Query: {}\".format(re.findall(r'\"(.*?)\"', value)[-1])\n",
    "        except:\n",
    "            return \"Query: None\"\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "for col in df.select_dtypes(include=object): \n",
    "    df[col] = df[col].apply( lambda x: tryconvert(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4327e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb6af0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['pagePath'].str.startswith('Query')].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e732cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "m = df[df['pagePath'].apply( lambda x: True if x.startswith('Query:') else False )]\n",
    "m[m['secondPagePath'].apply( lambda x: True if x.startswith('/curso/') else False )]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd00358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DICTIONARY OF ALL THE QUERY TERMS USERS LOOKED FOR - TO CROSSREFERENCE WITH COURSES CURRENTLY ON OFFER\n",
    "# Next step to take into consideration by how many users each of which was looked for. \n",
    "l = []\n",
    "m = df[df['pagePath'].apply( lambda x: True if x.startswith('Query:') else False )]['pagePath'].apply( lambda x: l.append(re.findall(r'\\s(.*)', x)[0].lower().replace('+', ' ')))\n",
    "text = ' '.join(l)\n",
    "filtered_sentence = remove_stopwords(text)\n",
    "s_ = [x for x in filtered_sentence.split(\" \") if len(x) > 2 ]\n",
    "dict(sorted(Counter(s_).items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a141a9ca",
   "metadata": {},
   "source": [
    "# Channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f84cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIMS = ['ga:channelGrouping'] \n",
    "METRICS = []\n",
    "\n",
    "response = get_report(analytics, DIMS, METRICS)\n",
    "\n",
    "df = ga_response_dataframe(response, DIMS, METRICS)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

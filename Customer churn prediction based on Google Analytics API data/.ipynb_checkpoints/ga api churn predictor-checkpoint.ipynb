{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44a80e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Analytics Reporting API V4.\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "import argparse\n",
    "from datetime import date, datetime\n",
    "\n",
    "from apiclient.discovery import build\n",
    "import httplib2\n",
    "from oauth2client import client\n",
    "from oauth2client import file\n",
    "from oauth2client import tools\n",
    "from tqdm import tqdm\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DIMS = ['ga:clientId', 'ga:deviceCategory', 'ga:userType', 'ga:daysSinceLastSession', 'ga:date']\n",
    "METRICS = ['ga:hits', 'ga:avgSessionDuration', 'ga:pageviews', 'ga:uniquePageviews']\n",
    "\n",
    "START_DATE = \"2020-09-01\"\n",
    "END_DATE = \"2021-11-20\"\n",
    "N = 50 # TRESHOLD OF PAGEVIEWS - DEPENDENT ON TIMEFRAME\n",
    "\n",
    "SCOPES = ['https://www.googleapis.com/auth/analytics.readonly']\n",
    "CLIENT_SECRETS_PATH = '' # Path to client_secrets.json file.\n",
    "VIEW_ID = '' # PUT IN OWN GOOGLE ANALYTICS VIEW ID\n",
    "\n",
    "\n",
    "def initialize_analyticsreporting():\n",
    "    \"\"\"\n",
    "    Initializes the analyticsreporting service object.\n",
    "\n",
    "    Returns:\n",
    "    analytics an authorized analyticsreporting service object.\n",
    "    \"\"\"\n",
    "    # Parse command-line arguments.\n",
    "    parser = argparse.ArgumentParser(\n",
    "      formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "      parents=[tools.argparser])\n",
    "    flags = parser.parse_args([])\n",
    "\n",
    "    # Set up a Flow object to be used if we need to authenticate.\n",
    "    flow = client.flow_from_clientsecrets(\n",
    "      CLIENT_SECRETS_PATH, scope=SCOPES,\n",
    "      message=tools.message_if_missing(CLIENT_SECRETS_PATH))\n",
    "\n",
    "    # Prepare credentials, and authorize HTTP object with them.\n",
    "    # If the credentials don't exist or are invalid run through the native client\n",
    "    # flow. The Storage object will ensure that if successful the good\n",
    "    # credentials will get written back to a file.\n",
    "    storage = file.Storage('analyticsreporting.dat')\n",
    "    credentials = storage.get()\n",
    "    if credentials is None or credentials.invalid:\n",
    "        credentials = tools.run_flow(flow, storage, flags)\n",
    "    http = credentials.authorize(http=httplib2.Http())\n",
    "\n",
    "    # Build the service object.\n",
    "    analytics = build('analyticsreporting', 'v4', http=http)\n",
    "\n",
    "    return analytics\n",
    "\n",
    "def get_report(analytics, dims, metrics):\n",
    "  # Use the Analytics Service Object to query the Analytics Reporting API V4.\n",
    "    requests_list =  [{\n",
    "            'viewId': VIEW_ID,\n",
    "            'dateRanges': [{'startDate': START_DATE, 'endDate': END_DATE}],\n",
    "            'dimensions': [{'name': name} for name in dims],\n",
    "            'metrics': [{'expression': exp} for exp in metrics],\n",
    "        \"samplingLevel\": \"LARGE\",\n",
    "        \"pageSize\": 100000\n",
    "    }]\n",
    "    return analytics.reports().batchGet(body={'reportRequests':requests_list }).execute()\n",
    "\n",
    "def report_dataframe(response, dims, metrics):\n",
    "    data_dic = {f\"{i}\": [] for i in dims + metrics}\n",
    "    for report in response.get('reports', []):\n",
    "        rows = report.get('data', {}).get('rows', [])\n",
    "        for row in rows:\n",
    "            for i, key in enumerate(dims):\n",
    "                data_dic[key].append(row.get('dimensions', [])[i]) # Get dimensions\n",
    "            dateRangeValues = row.get('metrics', [])\n",
    "            for values in dateRangeValues:\n",
    "                all_values = values.get('values', []) # Get metric values\n",
    "                for i, key in enumerate(metrics):\n",
    "                    data_dic[key].append(all_values[i])\n",
    "\n",
    "    df = pd.DataFrame(data=data_dic)\n",
    "    df.columns = [col.split(':')[-1] for col in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def report_clientid(analytics, user_ids):\n",
    "  # Use the Analytics Service Object to query the Analytics Reporting API V4.\n",
    "    report = []\n",
    "    \n",
    "    for user_id in tqdm(user_ids):\n",
    "        try: \n",
    "            data = analytics.userActivity().search(body={\n",
    "              \"viewId\": VIEW_ID,\n",
    "              \"dateRange\": {\n",
    "                 \"startDate\": START_DATE,\n",
    "                 \"endDate\": END_DATE\n",
    "              },\n",
    "               \"user\": {\n",
    "                 \"type\": \"CLIENT_ID\",\n",
    "                 \"userId\": user_id\n",
    "              }\n",
    "            }).execute()\n",
    "        except: \n",
    "            data = {}\n",
    "        \n",
    "        report.append(data)\n",
    "        \n",
    "    return report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01896811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_to_df(df, value):\n",
    "    for k, v in value.items():\n",
    "        df[k] = v\n",
    "    \n",
    "\n",
    "def report_dataframe_sessions(response):\n",
    "    # One list per user. Each item of which containing a list of sessions. Each session containing a list of activities.\n",
    "    l = []\n",
    "    for user in response: \n",
    "        for session in user['sessions']: \n",
    "            session_keys = list(session.keys())\n",
    "            session_keys.remove('activities')\n",
    "\n",
    "            dic = { key: session[key] for key in session_keys }\n",
    "            \n",
    "            try: \n",
    "                dic['user_id'] = session['activities'][0]['customDimension'][17]['value']\n",
    "            except: \n",
    "                pass\n",
    "\n",
    "            l.append(dic)\n",
    "    \n",
    "    df = pd.DataFrame(l)\n",
    "    return df\n",
    "        \n",
    "\n",
    "def report_dataframe_activities(response):\n",
    "    # One list per user. Each item of which containing a list of sessions. Each session containing a list of activities.\n",
    "    l = []\n",
    "    for user in response: \n",
    "        for session in user['sessions']: \n",
    "            session_id = session['sessionId']\n",
    "            for activity in session['activities']:\n",
    "                dic = {}\n",
    "                                \n",
    "                activity_keys = list(activity.keys())\n",
    "                \n",
    "                if 'customDimension' in activity_keys:\n",
    "                    for i in activity['customDimension']:\n",
    "                        if 'value' in i.keys():\n",
    "                            dic[i['index']] = i['value']\n",
    "                            \n",
    "                if 18 in dic.keys():       \n",
    "                    dic['user_id'] = dic.pop(18)\n",
    "                            \n",
    "                activity_keys.remove('customDimension')\n",
    "\n",
    "                for key in activity_keys:\n",
    "                    dic[key] = activity[key] \n",
    "            \n",
    "                dic['session_id'] = session_id\n",
    "                l.append(dic)\n",
    "    df = pd.DataFrame(l)\n",
    "        \n",
    "    return df\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcdd93c",
   "metadata": {},
   "source": [
    "# Calling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf834a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Documentation on google analytics dimensions and metrices\n",
    "# https://ga-dev-tools.web.app/dimensions-metrics-explorer/\n",
    "\n",
    "analytics = initialize_analyticsreporting()\n",
    "DIMS = ['ga:clientId', 'ga:deviceCategory', 'ga:userType', 'ga:daysSinceLastSession', 'ga:date', 'ga:country', 'ga:dimension18']\n",
    "METRICS = ['ga:hits', 'ga:avgSessionDuration', 'ga:pageviews', 'ga:uniquePageviews']\n",
    "\n",
    "response_users = get_report(analytics, DIMS, METRICS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec070ac",
   "metadata": {},
   "source": [
    "## Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55d72bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = report_dataframe(response_users, DIMS, METRICS)\n",
    "\n",
    "users = users.loc[users.dimension18 != 'NA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fffaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.clientId.value_counts().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18f0ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = users.clientId.value_counts().value_counts()\n",
    "fig,ax = plt.subplots(1)\n",
    "ax = a.plot(kind='bar')\n",
    "\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7026940e",
   "metadata": {},
   "source": [
    "# Target Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb602e19",
   "metadata": {},
   "source": [
    "1. Check distribution only for users with more than one visits\n",
    "2. Add column with time difference in days between that and the next session (or today)\n",
    "3. Define \"churned\" based on distrubtion of times between sessions. \n",
    "\n",
    "- suprsingly much cross device usage\n",
    "- remove outliers and e.g. company visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8570437",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_churn = users.copy()\n",
    "\n",
    "# Only select those that have visited more than once\n",
    "df_group = users_churn.groupby('dimension18').count()['date']\n",
    "returning_users = df_group[df_group > 1].index\n",
    "\n",
    "users_churn = users_churn.loc[users_churn['dimension18'].isin(returning_users)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04edb862",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_churn['date'] = pd.to_datetime(users_churn['date'], format='%Y%m%d')\n",
    "\n",
    "today = datetime.now()\n",
    "\n",
    "users_churn = users_churn.append(users_churn.drop_duplicates(\"dimension18\").assign(date=today), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8bcbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "users_churn['delta'] = np.nan\n",
    "users_churn['latestvisit'] = 0\n",
    "\n",
    "\n",
    "for i in np.unique(users_churn.dimension18.values): \n",
    "    df1 = users_churn.loc[users_churn.dimension18 == i]  \n",
    "    df1 = df1.sort_values('date', ascending=False)\n",
    "    \n",
    "    for x in range(1, df1.shape[0]):\n",
    "        delta = df1.iloc[x-1]['date'] - df1.iloc[x]['date']\n",
    "        \n",
    "        users_churn.loc[users_churn.index == df1.index[x], 'delta'] = delta.days \n",
    "    \n",
    "    users_churn.loc[users_churn.index == df1.index[1], 'latestvisit'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c45750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is realistic as a return rate? is it not specific campaigns/ event users come on the page for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa98e476",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_churn = users_churn.loc[users_churn.date != today]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b466bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_churn.sort_values(['dimension18', 'date'], ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b6e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_churn_returning = users_churn.loc[users_churn.latestvisit == 0]\n",
    "returned_users_delta = users_churn_returning['delta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458c648",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = returned_users_delta.value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422a4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1)\n",
    "ax = n.plot(kind='bar')\n",
    "\n",
    "fig.set_figwidth(20)\n",
    "fig.set_figheight(7)\n",
    "\n",
    "plt.yscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e92ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "returned_users_delta.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06442e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "delta_describe = returned_users_delta.describe()\n",
    "\n",
    "mean = delta_describe['mean']\n",
    "std = delta_describe['std']\n",
    "variance = delta_describe['std']**2\n",
    "\n",
    "x = np.arange(mean-0.1, mean+0.11,.001)\n",
    "\n",
    "f = np.exp(-np.square(x-mean)/2*variance)/(np.sqrt(2*np.pi*variance))\n",
    "\n",
    "plt.plot(x,f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc360cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_churn['zscore'] = np.abs((users_churn.delta - returned_users_delta.mean())/returned_users_delta.std(ddof=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb37d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_churn.loc[:, 'churned'] = 0\n",
    "users_churn.loc[users_churn.zscore > 3, 'churned'] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1967c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(users_churn['deviceCategory'])\n",
    "users_churn = users_churn.drop('deviceCategory', axis = 1)\n",
    "# Join the encoded df\n",
    "users_churn = users_churn.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509a5860",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_churn.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c57f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "users_churn = users_churn.drop(columns=['clientId', 'delta', 'zscore', 'userType', 'daysSinceLastSession', 'country'])\n",
    "\n",
    "cols = ['hits', 'avgSessionDuration', 'pageviews', 'uniquePageviews']\n",
    "users_churn.loc[:, cols] = users_churn[cols].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "users_churn.loc[:, cols] = users_churn[cols][(np.abs(stats.zscore(users_churn[cols])) < 3).all(axis=1)]\n",
    "\n",
    "users_churn.loc[:, 'sessions'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059005a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "users_churn.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0455717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "\n",
    "for i in np.unique(users_churn.dimension18.values): \n",
    "    dic = {}\n",
    "\n",
    "    df1 = users_churn.loc[users_churn.dimension18 == i]  \n",
    "    df1 = df1.sort_values('date', ascending=False)\n",
    "    \n",
    "    dic['dimension18'] = i\n",
    "    \n",
    "    dic['hits'] = df1.hits.mean()\n",
    "    dic['avgSessionDuration'] = df1.avgSessionDuration.mean()\n",
    "    dic['pageviews'] = df1.pageviews.mean()\n",
    "    dic['uniquePageviews'] = df1.uniquePageviews.mean()\n",
    "    \n",
    "    dic['churned'] = df1.churned.values[0]\n",
    "    dic['sessions'] = df1.sessions.sum()\n",
    "    \n",
    "    dic['desktop'] = df1.desktop.sum()\n",
    "    dic['mobile'] = df1.mobile.sum()\n",
    "    dic['tablet'] = df1.tablet.sum()\n",
    "    \n",
    "    l.append(dic)\n",
    "    \n",
    "df_users = pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d6dd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highly unbalanced data, especially in terms of target: churned\n",
    "df_users.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f75b9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Increase the size of the heatmap.\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# Set the range of values to be displayed on the colormap from -1 to 1, and set the annotation to True to display the correlation values on the heatmap.\n",
    "heatmap = sns.heatmap(df_users.corr(), vmin=-1, vmax=1, annot=True)\n",
    "\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':12}, pad=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48af3a5c",
   "metadata": {},
   "source": [
    "## Sessions and Hits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322f37ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INFORMATION ON A SESSION LEVEL\n",
    "# PURPOSFULLY LIMTIED TO :150\n",
    "response = report_clientid(analytics, users[\"clientId\"][:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58412d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0864c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = report_dataframe_sessions(response)\n",
    "hits = report_dataframe_activities(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9dc821",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.drop(columns=[\"userType\", \"daysSinceLastSession\", \"date\", \"clientId\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65453b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits.update(hits.loc[hits['activityType'] == 'EVENT']['event'].apply(lambda x : x[\"eventCategory\"] + \"_\" + x[\"eventAction\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0b7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = hits.fillna(0)\n",
    "hits = hits.loc[~(hits['user_id']==0)]\n",
    "\n",
    "categorical_cols = ['channelGrouping'] \n",
    "df_h = pd.get_dummies(hits, columns = categorical_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5af65f",
   "metadata": {},
   "source": [
    "## Merge dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494a0877",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(hits, df_users, left_on=\"user_id\", right_on=\"dimension18\").drop(columns=['dimension18'])\n",
    "result = pd.merge(result, sessions, left_on=\"user_id\", right_on=\"user_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1038f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e74eb28",
   "metadata": {},
   "source": [
    "# Churnrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9242314",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_deleted = ['dataSource', 4, 34, 47, 48, 36, 33, 45, 7, 19, 20, 21, 32, 37, 41, 60, 62, 63, 64, 65, 66, 68, 35, 'hostname', 'landingPagePath', 46, 67, 8, 10, 42, 17, 44, 'deviceCategory', 'platform']\n",
    "cols = list(set(result.columns) & set(tb_deleted))\n",
    "\n",
    "result = result.drop(columns=cols)\n",
    "result = result.rename(columns={23: 'user_professionalspecialtycode', 25: 'user_professionaldesidnationcode', 22: 'registrationdate'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe45e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(columns= ['activityTime', 'source', 'medium', 'keyword', 'event', 'session_id', 'activityType', 'registrationdate', 'sessionId', 'pageview'])\n",
    "\n",
    "# granularity on a user level\n",
    "\n",
    "# include: user_professionalspecialtycode, user_professionaldesidnationcode\n",
    "# drop: 'activityTime', 'source', 'medium', 'keyword', 'event', 'session_id', 'activityType'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dcb67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result.loc[:, 'is_campaign'] = 1\n",
    "result.loc[result.campaign == '(not set)', 'is_campaign'] = 0\n",
    "result = result.drop('campaign', axis=1)\n",
    "\n",
    "\n",
    "\n",
    "for i in ['user_professionalspecialtycode', 'user_professionaldesidnationcode', 'channelGrouping']:\n",
    "\n",
    "    one_hot = pd.get_dummies(result[i])\n",
    "    result = result.drop(i, axis = 1)\n",
    "    result = result.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b4118a",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result[['user_id', 'is_campaign', 'AI', 'FMG', 'IM', 'OS', 'EE', 'GD', 'NR', '(Other)',\n",
    "       'Direct', 'Email', 'Referral']].groupby(['user_id']).agg({\n",
    "    'is_campaign' : 'max', \n",
    "    'AI' : 'first', \n",
    "    'FMG' : 'first', \n",
    "    'IM' : 'first', \n",
    "    'OS' : 'first' , \n",
    "    'EE' : 'first', \n",
    "    'GD' : 'first', \n",
    "    'NR' : 'first', \n",
    "    '(Other)' : 'mean',\n",
    "    'Direct' : 'mean', \n",
    "    'Email' : 'mean', \n",
    "    'Referral' : 'mean'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b4ddde",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_ = pd.merge(result, df_users, left_index=True, right_on=\"dimension18\").drop(columns=['dimension18'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0123b2d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebc7326",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "\n",
    "# evaluate xgboost random forest algorithm for classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from xgboost import XGBRFClassifier\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X = result_.drop(['churned'], axis=1)\n",
    "enc.fit(X)\n",
    "X = enc.transform(X).toarray()\n",
    "\n",
    "y = result_['churned']\n",
    "# define the model\n",
    "model = XGBRFClassifier(n_estimators=100, subsample=0.9, colsample_bynode=0.2)\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7084737b",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3212984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clusters = 3\n",
    "model = KMeans(init = 'k-means++', \n",
    "               n_clusters = clusters, \n",
    "               n_init = 12)\n",
    "model.fit(X)\n",
    "\n",
    "labels = model.labels_\n",
    "print(labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b063ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_num'] = labels\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D # 3d plot\n",
    "\n",
    "\n",
    "fig = plt.figure(1)\n",
    "plt.clf()\n",
    "ax = Axes3D(fig, \n",
    "            rect = [0, 0, .95, 1], \n",
    "            elev = 48, \n",
    "            azim = 134)\n",
    "\n",
    "plt.cla()\n",
    "ax.scatter(result_['sessions'], result_['pageviews'], result_['hits'], \n",
    "           c = df['cluster_num'], \n",
    "           s = 200, \n",
    "           cmap = 'spring', \n",
    "           alpha = 0.5, \n",
    "           edgecolor = 'darkgrey')\n",
    "\n",
    "ax.set_ylabel('pageviews', \n",
    "              fontsize = 16)\n",
    "ax.set_zlabel('hits', \n",
    "              fontsize = 16)\n",
    "\n",
    "plt.savefig('3d_plot.png')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
